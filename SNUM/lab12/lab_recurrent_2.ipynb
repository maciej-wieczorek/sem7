{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebvqJaNU9bkH"
      },
      "source": [
        "# Elementy Inteligencji Obliczeniowej - Sieci Neuronowe\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Prowadzący:** Jakub Bednarek<br>\n",
        "**Kontakt:** jakub.bednarek@put.poznan.pl<br>\n",
        "**Materiały:** [Strona WWW](http://jakub.bednarek.pracownik.put.poznan.pl)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0tVMrm99g5w"
      },
      "source": [
        "## Uwaga\n",
        "\n",
        "* **Aby wykonać polecenia należy najpierw przejść do trybu 'playground'. File -> Open in Playground Mode**\n",
        "* Nowe funkcje Colab pozwalają na autouzupełnianie oraz czytanie dokumentacji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlq47LA0BuBB"
      },
      "source": [
        "## Cel ćwiczeń:\n",
        "- zapoznanie się z rekurencyjnymi sieciami neuronowymi,\n",
        "- stworzenie modelu sieci z warstwami rekurencyjnymi dla zbioru danych MNIST,\n",
        "- stworzenie własnych implementacji warstwami neuronowych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SxLU8paIDmUe",
        "outputId": "973390c4-5aee-4456-e4d9-f4c162717038"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "scL5_bHTD-M7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, LSTM, LSTMCell, SimpleRNNCell\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adadelta, RMSprop\n",
        "from tensorflow.python.keras import backend as K\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "wV_u-YBWEJ8X",
        "outputId": "1125ba20-3008-4697-fe68-906e775b7359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11490434/11490434 [==============================] - 9s 1us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32')  # shape: 60000, 28, 28\n",
        "x_test = x_test.astype('float32')    # shape: 10000, 28, 28\n",
        "x_train /= 255  # normalizacja wartości do przedziału [0, 1]\n",
        "x_test /= 255\n",
        "\n",
        "y_train = to_categorical(y_train, 10)  # zamiana etykiety na one-hot encoding; np. 2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "y_test = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppmDSGoyFuJ9"
      },
      "source": [
        "## Sieci rekurencyjne\n",
        "http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "\n",
        "https://www.tensorflow.org/guide/keras/rnn\n",
        "\n",
        "https://www.tensorflow.org/guide/function\n",
        "\n",
        "http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "\n",
        "http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/\n",
        "\n",
        "Przykładowy model z warstwą rekurencyjną dla danych MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ViqotGlHGy9t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class RecurrentModel(Model):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(RecurrentModel, self).__init__(name='my_model')\n",
        "        self.num_classes = num_classes\n",
        "        # Define your layers here.\n",
        "        self.lstm_1 = LSTM(128, activation='relu')\n",
        "        self.dense_1 = Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define your forward pass here,\n",
        "        # using layers you previously defined (in `__init__`).\n",
        "        x = self.lstm_1(inputs)\n",
        "        return self.dense_1(x)\n",
        "\n",
        "model = RecurrentModel(num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "jFs-QBFtEp0s",
        "outputId": "085c2e9a-e4ba-4de7-e818-18c3e02526e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:From c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "1875/1875 [==============================] - 36s 18ms/step - loss: 0.5585 - accuracy: 0.8278\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.1434 - accuracy: 0.9590\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x196824bcd90>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(optimizer=RMSprop(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgtZzVYg1361"
      },
      "source": [
        "### Zadanie 1\n",
        "Rozszerz model z powyższego przykładu o kolejną warstwę rekurencyjną przed gęstą warstwą wyjściową.\n",
        "\n",
        "Standardowe sieci neuronowe generują jeden wynik na podstawie jednego inputu, natomiast sieci rekurencyjne przetwarzają dane sekwencyjnie, w każdym kroku łącząc wynik poprzedniego przetwarzania i aktualnego wejścia. Dlatego domyślnym wejściem sieci neuronowej jest tensor 3-wymiarowy ([batch_size,sequence_size,sample_size]).\n",
        "Domyślnie warstwy rekurencyjne w Kerasie zwracają tylko wyniki przetwarzania ostatniego\n",
        "kroku (otrzymują tensor 3-wymiarowy, zwracają tensor 2-wymiarowy). Jeśli chcesz zwrócić sekwencje wyników wszystkich kroków przetwarzania dla warstwy rekurencyjnej, musisz ustawić parametr return_sequences=True.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MSJUzxAc15uZ"
      },
      "outputs": [],
      "source": [
        "class RecurrentModel(Model):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(RecurrentModel, self).__init__(name='my_model')\n",
        "        self.num_classes = num_classes\n",
        "        # Define your layers here.\n",
        "        self.lstm_1 = LSTM(128, activation='relu', return_sequences=True)\n",
        "        self.lstm_2 = LSTM(128, activation='relu')\n",
        "        self.dense_1 = Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define your forward pass here,\n",
        "        # using layers you previously defined (in `__init__`).\n",
        "        x = self.lstm_1(inputs)\n",
        "        x = self.lstm_2(x)\n",
        "        return self.dense_1(x)\n",
        "\n",
        "model = RecurrentModel(num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 66s 33ms/step - loss: 0.4833 - accuracy: 0.8486\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 64s 34ms/step - loss: 0.1270 - accuracy: 0.9650\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x196a8932ac0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(optimizer=RMSprop(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYDLWjdseB4H"
      },
      "source": [
        "### Zadanie 2\n",
        "Wykorzystując model z przykładu, napisz sieć rekurencyjną przy użyciu SimpleRNNCell.\n",
        "\n",
        "Cell implementuje tylko operacje wykonywane przez warstwę\n",
        "rekurencyjną dla jednego kroku. Warstwy rekurencyjne w każdym kroku\n",
        "łączą wynik operacji poprzedniego kroku i aktualny input.\n",
        "Wykorzystaj pętle for do wielokrotnego wywołania komórki SimpleRNNCell (liczba kroków to liczba elementów w sekwencji). Aby wywołać SimpleRNNCell dla pojedynczego wejścia i stanu należy użyć jej metody ```call``` analogicznie jak w przypadku własnych modeli (tzn. ```my_model(input)```).\n",
        "\n",
        "\n",
        "\n",
        "Wywołanie zainicjalizowanej komórki rekurencyjnej wymaga podania aktualnego inputu i **listy macierzy** (w dokumentacji jest błąd, że ma to być macierz) stanów ukrytych poprzedniego kroku (SimpleRNNCell ma jeden stan, LSTMCell w następnym zadaniu ma dwa stany).\n",
        "\n",
        "Trzeba zainicjalizować ukryty stan warstwy wartościami początkowymi (można wykorzystać rozkład normalny - tf.random.normal)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6yZ8yKmbee44"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "('Keyword argument not understood:', 'return_states')",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m             h\u001b[38;5;241m.\u001b[39mappend(state)\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense_1(x)\n\u001b[1;32m---> 20\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mRecurrentModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[19], line 7\u001b[0m, in \u001b[0;36mRecurrentModel.__init__\u001b[1;34m(self, num_classes)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes \u001b[38;5;241m=\u001b[39m num_classes\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Define your layers here.\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnnCell \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleRNNCell\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense_1 \u001b[38;5;241m=\u001b[39m Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\rnn\\simple_rnn.py:138\u001b[0m, in \u001b[0;36mSimpleRNNCell.__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, kernel_regularizer, recurrent_regularizer, bias_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_caching_device \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_caching_device\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     )\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m units\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m activations\u001b[38;5;241m.\u001b[39mget(activation)\n",
            "File \u001b[1;32mc:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\rnn\\dropout_rnn_cell_mixin.py:43\u001b[0m, in \u001b[0;36mDropoutRNNCellMixin.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_non_trackable_mask_cache()\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:3812\u001b[0m, in \u001b[0;36mBaseRandomLayer.__init__\u001b[1;34m(self, seed, force_generator, rng_type, **kwargs)\u001b[0m\n\u001b[0;32m   3784\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mno_automatic_dependency_tracking\n\u001b[0;32m   3785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   3786\u001b[0m     \u001b[38;5;28mself\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, force_generator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, rng_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   3787\u001b[0m ):\n\u001b[0;32m   3788\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the BaseRandomLayer.\u001b[39;00m\n\u001b[0;32m   3789\u001b[0m \n\u001b[0;32m   3790\u001b[0m \u001b[38;5;124;03m    Note that the constructor is annotated with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;124;03m        *class\u001b[39;00m\n\u001b[0;32m   3811\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_generator \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mRandomGenerator(\n\u001b[0;32m   3814\u001b[0m         seed, force_generator\u001b[38;5;241m=\u001b[39mforce_generator, rng_type\u001b[38;5;241m=\u001b[39mrng_type\n\u001b[0;32m   3815\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:340\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m allowed_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimplementation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    338\u001b[0m }\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# Validate optional keyword arguments.\u001b[39;00m\n\u001b[1;32m--> 340\u001b[0m \u001b[43mgeneric_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# Mutable properties\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;66;03m# Indicates whether the layer's weights are updated during training\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# and whether the layer's updates are run during training.\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(trainable, \u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m     )\n\u001b[0;32m    351\u001b[0m ):\n",
            "File \u001b[1;32mc:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\generic_utils.py:514\u001b[0m, in \u001b[0;36mvalidate_kwargs\u001b[1;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kwarg \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwarg \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_kwargs:\n\u001b[1;32m--> 514\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(error_message, kwarg)\n",
            "\u001b[1;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'return_states')"
          ]
        }
      ],
      "source": [
        "class RecurrentModel(Model):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(RecurrentModel, self).__init__(name='my_model')\n",
        "        self.num_classes = num_classes\n",
        "        # Define your layers here.\n",
        "        self.rnnCell = SimpleRNNCell(128, activation='relu')\n",
        "        self.dense_1 = Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define your forward pass here,\n",
        "        # using layers you previously defined (in `__init__`).\n",
        "        h = []\n",
        "        h.append(self.rnnCell.get_initial_state(batch_size=1, dtype=tf.float32))\n",
        "        for input in inputs:\n",
        "            x, state = self.rnnCell(input, h)\n",
        "            h.append(state)\n",
        "        return self.dense_1(x)\n",
        "\n",
        "model = RecurrentModel(num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 10) and (28, 10) are incompatible\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mRMSprop(),\n\u001b[0;32m      2\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filen4ry9f7w.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 10) and (28, 10) are incompatible\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=RMSprop(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyPGkC6oiEd5"
      },
      "source": [
        "### Zadanie 3\n",
        "Zamień komórkę rekurencyjną z poprzedniego zadania na LSTMCell (LSTMCell ma dwa stany ukryte)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5MPQ1UcigN5"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prwjaEv2efs3"
      },
      "source": [
        "### Zadanie 4\n",
        "Wykorzystując model z poprzedniego zadania, stwórz model sieci\n",
        "neuronowej z własną implementacją prostej warstwy rekurencyjnej.\n",
        "- w call zamień self.lstm_cell_layer(x) na wywołanie własnej metody np. self.cell(x)\n",
        "- w konstruktorze modelu usuń inicjalizację komórki LSTM i zastąp ją inicjalizacją warstw potrzebnych do stworzenia własnej komórki rekurencyjnej,\n",
        "- stwórz metodę cell() wykonującą operacje warstwy rekurencyjnej,\n",
        "- prosta warstwa rekurencyjna konkatenuje poprzedni wyniki i aktualny input, a następnie przepuszcza ten połączony tensor przez warstwę gęstą (Dense)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGQr50EafxSH"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3sOaUu3b77l"
      },
      "source": [
        "### Zadanie 5\n",
        "\n",
        "Na podstawie modelu z poprzedniego zadania stwórz model z własną implementacją warstwy LSTM. Dokładny i zrozumiały opis działania warstwy LSTM znajduje się na [stronie](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kyu4YijDcA13"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
