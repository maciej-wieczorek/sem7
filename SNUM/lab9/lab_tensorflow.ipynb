{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebvqJaNU9bkH"
      },
      "source": [
        "# Elementy Inteligencji Obliczeniowej - Sieci Neuronowe\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Prowadzący:** Jakub Bednarek<br>\n",
        "**Kontakt:** jakub.bednarek@put.poznan.pl<br>\n",
        "**Materiały:** [Strona WWW](http://jakub.bednarek.pracownik.put.poznan.pl)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0tVMrm99g5w"
      },
      "source": [
        "## Uwaga\n",
        "\n",
        "* **Aby wykonać polecenia należy najpierw przejść do trybu 'playground'. File -> Open in Playground Mode**\n",
        "* Nowe funkcje Colab pozwalają na autouzupełnianie oraz czytanie dokumentacji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlq47LA0BuBB"
      },
      "source": [
        "## Cel ćwiczeń:\n",
        "\n",
        "* wprowadzenie biblioteki TensorFlow,\n",
        "* prezentacja podejścia Eager oraz Graph Execution,\n",
        "* ukazanie różnic i podobieństw pomiędzy NumPy a TensorFlow,\n",
        "* algorytm wstecznej propagacji błędu w TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0AoiF16OTow"
      },
      "source": [
        "## Tensorflow\n",
        "\n",
        "Tensorflow to biblioteka przeznaczona do uczenia maszynowego oraz przetwarzania Big Data. Jej podstawy zostały zbudowane na wzór NumPy, którego poszczególne elementy zostały zaprezentowane na poprzednich zajęciach.\n",
        "Co wyróżnia Tensorflow to możliwość korzystania zarówno z CPU, GPU jak i łączenia jednostek obliczeniowych w klastry.\n",
        "\n",
        "Korzystając z Colab nie potrzebujesz wykonywać żadnych dodatkowych kroków w celu konfiguracji.\n",
        "\n",
        "Najnowszą wersją biblioteki jest TensorFlow 2.x. Aby ją aktywować wywołaj poniższe polecenie.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2ovUb2T9CbQv",
        "outputId": "202e5a14-fc20-4caf-e673-39819cbff9db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorflow_version` not found.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyOQAsNXECp0"
      },
      "source": [
        "## Model działania biblioteki Tensorflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUuN3WIZEFaT"
      },
      "source": [
        "### Eager Execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBy3wd9GSXa0"
      },
      "source": [
        "Tensorflow w wersji 2.x pozwala na prawie identyczne wykonanie operacji jak w przypadku biblioteki NumPy, poznanej na poprzednich zajęciach. Operacje wykonywane są w momencie ich wywołania. Podejście takie nazywa się **Eager Execution**.\n",
        "\n",
        "Poniżej przedstawione zostało porównanie wykonania tego samego zadania w NumPy oraz w Tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jl7PpJ5OOVNj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\macie\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# import bibliotek\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "GKGuFNGnTa9c",
        "outputId": "da95dd3a-9d4e-4e58-dd2d-0d4d9ae61de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumPy array:\n",
            " [[-0.57244802  1.0388057  -1.23343627 -0.51164051  0.60041074]\n",
            " [-0.42555533 -0.69458515 -1.92222728  0.31513489  0.7444066 ]\n",
            " [-0.92871813 -0.85300236 -0.07310983 -0.08381971 -1.13377545]\n",
            " [ 0.01722041  0.08214671  2.062554    1.72814354  0.11842006]\n",
            " [ 0.11586263 -0.16373711  0.0396229  -0.90458094  1.36083982]] \n",
            "\n",
            "Tensorflow array:\n",
            " tf.Tensor(\n",
            "[[ 3.6817964e-02  1.4883517e-03  2.0479578e-01 -3.9401954e-01\n",
            "  -7.0061707e-01]\n",
            " [ 1.1470996e+00  1.4975184e-01  3.8299322e-02  1.5166159e-01\n",
            "   1.5568312e+00]\n",
            " [-7.4253267e-01 -9.7911805e-01 -3.6880139e-01  2.2500962e-01\n",
            "  -1.7379435e+00]\n",
            " [-5.0928360e-01 -4.0548992e-01 -1.1021280e+00  7.7340382e-01\n",
            "   6.6687506e-01]\n",
            " [ 1.1033177e+00  9.7144461e-01  8.5770470e-01 -9.1716462e-01\n",
            "   8.3898711e-01]], shape=(5, 5), dtype=float32) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# przykładowa alokacja danych:\n",
        "np_arr = np.zeros([5, 5])\n",
        "tf_arr = tf.zeros([5, 5])\n",
        "\n",
        "np_arr = np.ones([5, 5])\n",
        "tf_arr = tf.ones([5, 5])\n",
        "\n",
        "np_arr = np.array([1, 2, 3, 4, 5])\n",
        "tf_arr = tf.constant([1, 2, 3, 4, 5])\n",
        "\n",
        "np_arr = np.random.normal(0, 1, [5, 5])\n",
        "tf_arr = tf.random.normal([5, 5], 0, 1)\n",
        "\n",
        "print('NumPy array:\\n', np_arr, '\\n')\n",
        "print('Tensorflow array:\\n', tf_arr, '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDAxwKNDUMrH"
      },
      "source": [
        "### Zadanie 1\n",
        "\n",
        "Zaalokuj tablicę samych zer o wymiarze 2 x 2. Następnie utwórz tablicę jedynek o tym samym wymiarze (wykorzystaj funkcję ones_like)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lnt4cj4vWhms"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0.]\n",
            " [0. 0.]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[1. 1.]\n",
            " [1. 1.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# alokacja zer\n",
        "z = tf.zeros([2, 2])\n",
        "\n",
        "# alokacja jedynek\n",
        "o = tf.ones_like(z)\n",
        "\n",
        "print(z)\n",
        "print(o)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAy5wHavW0Gc"
      },
      "source": [
        "Również operacje na danych wyglądają podobnie w Tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CsL2HNwZXcYl",
        "outputId": "1c08568b-b802-4150-d60e-568518e83539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([11.224972   3.4641016  6.       ], shape=(3,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "a = tf.constant([1, 2, 3], dtype=tf.float32)\n",
        "b = tf.constant([5, 2, 3], dtype=tf.float32)\n",
        "\n",
        "c = a + b\n",
        "d = a * b\n",
        "e = a ** 2 + b ** 3\n",
        "f = tf.sqrt(e)\n",
        "\n",
        "print(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIo9g-OZI-jv"
      },
      "source": [
        "### Zmienne w TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZW2QB-HJDxu"
      },
      "source": [
        "Tensorflow posiada specjalny rodzaj obiektów, które reprezentują **zmienne uczone**. Poniżej zostało zaprezentowane wykorzystanie zmiennych uczonych.\n",
        "\n",
        "Każda operacja w TensorFlow tworzy na wyjściu **tensor**, przez który można automatycznie propagować błąd."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "tpLPMsD0JeB_",
        "outputId": "d09ad9c4-bf89-4e86-932a-0fd595b98899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([[32.275608 29.468405 27.037966 29.436054 32.247616]], shape=(1, 5), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# zmienne uczone dla pojedynczej warstwy neuronowej (5 neuronów)\n",
        "w = tf.Variable(tf.random.uniform([128, 5]))\n",
        "b = tf.Variable(tf.random.uniform([5]))\n",
        "\n",
        "# definicja warstwy w pełni połączonej\n",
        "def neuron_layer(x):\n",
        "  return x @ w + b\n",
        "\n",
        "# losowy wektor wejściowy i inferencja (odpytanie) sieci neuronowej\n",
        "x = tf.random.uniform([1, 128])\n",
        "y = neuron_layer(x)\n",
        "\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ah23dQ-KYdI"
      },
      "source": [
        "Zmienne w TensorFlow można dowolnie modyfikować operacją *assign* (oraz jej pochodnymi wersjami).\n",
        "\n",
        "**Uwaga:** Zmienne oraz wszelkie tensory w TensorFlow można przekształcić do tablicy Numpy wywołując funkcję *.numpy()*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "DFaFBDxdKe4S",
        "outputId": "a5294563-3937-4735-88ec-1194599c3d99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.89798987 0.94532    0.6101177  0.4924314  0.52221274]\n",
            "[1.8979899  0.94532    0.6101177  1.4924314  0.52221274]\n",
            "[0.89798987 0.94532    0.6101177  0.4924314  0.52221274]\n",
            "[1. 2. 3. 4. 5.]\n"
          ]
        }
      ],
      "source": [
        "# inicjalizacja zmiennej z losowymi wartościami\n",
        "b = tf.Variable(tf.random.uniform([5]))\n",
        "\n",
        "print(b.numpy())\n",
        "\n",
        "# wykonanie operacji dodawania na zmiennej\n",
        "b.assign_add([1, 0, 0, 1, 0])\n",
        "\n",
        "print(b.numpy())\n",
        "\n",
        "# wykonanie operacji odejmowania na zmiennej\n",
        "b.assign_sub([1, 0, 0, 1, 0])\n",
        "\n",
        "print(b.numpy())\n",
        "\n",
        "# wykonanie operacji przypisania na zmiennej\n",
        "b.assign([1, 2, 3, 4, 5])\n",
        "\n",
        "print(b.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sh_nuvpLfJu"
      },
      "source": [
        "### Funkcje aktywacji i straty w TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbUbMgx0LkXd"
      },
      "source": [
        "TensorFlow jest biblioteką przygotowaną do **Machine Learningu**. Wiele operacji bardzo często się powtarza w wielu zagadnieniach, np. funkcje aktywacji, funkcje straty, metryki, rodzaje warstw (operacji), itp. Stąd, w bilbiotece tej możemy znaleźć już gotowe komponenty, które można z łatwością wykorzystać.\n",
        "\n",
        "Poniżej zaprezentowane zostały gotowe funkcje aktywacji oraz straty."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "v_Z84f4NMI0_",
        "outputId": "2ba4bdaf-7ee3-44ba-a283-aadd755bbbff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relu: [0.         0.3031428  0.16773343 0.         0.0151546 ]\n",
            "Sigmoid: [0.33170736 0.57521063 0.5418353  0.43772638 0.5037886 ]\n",
            "Softmax: [0.10283129 0.28053695 0.24500926 0.1612842  0.21033834]\n",
            "Tangens hiperboliczny: [-0.604668    0.29418603  0.1661779  -0.24528955  0.01515344] \n",
            "\n",
            "MSE: tf.Tensor([0.17484263 0.14706   ], shape=(2,), dtype=float32)\n",
            "MAE: tf.Tensor([0.3804394  0.31617627], shape=(2,), dtype=float32)\n",
            "CE: tf.Tensor([4.821745 3.1063  ], shape=(2,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "a = tf.random.uniform([5], -1, 1)\n",
        "\n",
        "a_relu = tf.nn.relu(a)\n",
        "a_sigmoid = tf.nn.sigmoid(a)\n",
        "a_softmax = tf.nn.softmax(a, -1)\n",
        "a_tanh = tf.nn.tanh(a)\n",
        "\n",
        "print('Relu:', a_relu.numpy())  # max(x, 0)\n",
        "print('Sigmoid:', a_sigmoid.numpy())  # wyjście w przedziale (0, 1)\n",
        "print('Softmax:', a_softmax.numpy())  # wyjście w przedziale (0, 1) a suma jest równa 1\n",
        "print('Tangens hiperboliczny:', a_tanh.numpy(), '\\n')\n",
        "\n",
        "y = tf.random.uniform([2, 5], 0, 1)  # batch o wielkości 2\n",
        "y_hat = tf.random.uniform([2, 5], 0, 1)\n",
        "\n",
        "y_mse = tf.losses.mean_squared_error(y_hat, y)  # dla każdego elementu w batchu błąd jest wyliczony osobno\n",
        "y_mae = tf.losses.mean_absolute_error(y_hat, y)\n",
        "y_ce = tf.losses.categorical_crossentropy(y_hat, y, from_logits=True)  # from_logits oznacza, że funkcja aktywacji (softmax) będzie wywołana wewnątrz funkcji straty, a więc wyjście z sieci powinno być liniowe\n",
        "\n",
        "print('MSE:', y_mse)\n",
        "print('MAE:', y_mae)\n",
        "print('CE:', y_ce)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxSdsMUWD9ci"
      },
      "source": [
        "### Graph Execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJIwUfddR9Gl"
      },
      "source": [
        "Na potrzeby optymalizacji Google wprowadziło (przywróciło) możliwość definiowania grafów przetwarzania. Przetwarzanie grafowe polega na przekształceniu ciągu operacji do grafu, który następnie jest optymalizowany (np. poprzez zastąpienie instrukcji 'for' przez 'tf.while_loop').\n",
        "\n",
        "Aby zoptymalizować działanie kodu należy umieścić dane operacje w definicji funkcji opatrzonej w adnotację  @tf.function.\n",
        "\n",
        "**Uwaga**\n",
        "Po przekształceniu na graf tracimy możliwość łatwego debugowania kodu. Operacje przekształcane są do niskopoziomowej reprezentacji TensorFlow, znanej z wersji 1.x."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ets0mmTSUVsK"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# funkcja pomocnicza do mierzenia czasu wykonania funkcji\n",
        "\n",
        "def speed_test(iters, func, *arg):\n",
        "\n",
        "  start = time.time()\n",
        "  for i in range(iters):\n",
        "    func(*arg)\n",
        "  end = time.time()\n",
        "\n",
        "  return end - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OS0cUgx3E5um"
      },
      "outputs": [],
      "source": [
        "# część wspólna operacji wywołanych w graph i eager execution\n",
        "def eager_op(inputs):\n",
        "  x = inputs ** 2\n",
        "  z = tf.transpose(tf.ones_like(x))\n",
        "\n",
        "  for i in range(100):\n",
        "    # @ oznacza operację matmul\n",
        "    x = inputs @ x\n",
        "\n",
        "  # ile razy wywoła się ta linia w graph a ile w eager execution i dlaczego?\n",
        "  print('Ops function executed')\n",
        "\n",
        "  return x\n",
        "\n",
        "# graph execution wykonuje dokładnie te same operacje\n",
        "@tf.function\n",
        "def graph_op(inputs):\n",
        "  return eager_op(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "gn-jG-qcTbEo",
        "outputId": "1c682b48-a2b1-446d-fa96-147c933e6859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------ Eager Execution -----------\n",
            "Ops function executed\n",
            "Ops function executed\n",
            "Ops function executed\n",
            "Ops function executed\n",
            "Ops function executed\n",
            "Ops function executed\n",
            "Ops function executed\n",
            "Ops function executed\n",
            "Ops function executed\n",
            "Ops function executed\n",
            "5.582585096359253 sec\n",
            "------------ Graph Execution -----------\n",
            "4.436305522918701 sec\n"
          ]
        }
      ],
      "source": [
        "a = tf.random.uniform([1024, 1024], 0, 1)\n",
        "\n",
        "print('------------ Eager Execution -----------')\n",
        "print(speed_test(10, eager_op, a), 'sec')\n",
        "\n",
        "print('------------ Graph Execution -----------')\n",
        "print(speed_test(10, graph_op, a), 'sec')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ-XK5nUEUWd"
      },
      "source": [
        "## Algorytm wstecznej propagacji błędu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWWYxKRmguWl"
      },
      "source": [
        "Do wyprowadzenia wzorów na aktualizację zmiennych w algorytmie niezbędna jest znajomość zagadnień **chain-rule** oraz **multivariable chain-rule**. Poza podstawową wiedzą z matematyki są to jedyne niezbędne zagadnienia.\n",
        "\n",
        "### Chain-rule & Multivariable Chain-rule\n",
        "\n",
        "Poniżej zostały zaprezentowane zagadnienia **chain-rule** oraz **multivariable chain-rule** w sposób intuicyjny (i graficzny). Poniższa notacja została zaczerpnięta z sieci neuronowych, aby skojarzyć związek z algorytmem **backpropagation**.\n",
        "\n",
        "#### Chain-rule\n",
        "\n",
        "Jest to reguła opierająca się na pochodnej funkcji złożonej. W graficzny sposób można to pokazać następująco:\n",
        "\n",
        "![chain-rule](https://drive.google.com/uc?id=1S8pSUrrOzoisKr8d8YJaQHNLYgEq2dpk)\n",
        "\n",
        "Gdzie $L$ to pewna funkcja dla której liczymy pochodną względem zmiennej $w$. Jak widać, $L$ zależy od $y$, który zależy od $z$ który dopiero zależy bezpośrednio od $w$. Zależności tworzą łańcuch, skąd pochodzi nazwa **chain-rule**.\n",
        "\n",
        "#### Multivariable Chain-rule\n",
        "\n",
        "W przypadku gdy \"łańcuch\" w pewnym momencie się rozgałęzia, dalej możemy korzystać z zasady **chain-rule**, jednak tym razem przybiera ona formę nieco inną (lecz dalej intuicyjną):\n",
        "\n",
        "![multivariable-chain-rule](https://drive.google.com/uc?id=13WH6JXd_5rnTkyToKrBcCZDPdUXCqoT8)\n",
        "\n",
        "W tym przypadku, pochodna funkcji $L$ po zmiennej $z$ wyrażona jest jako suma pochodnych funkcji złożonych odpowiednio $y_1$ oraz $y_2$. Nic nie stoi na przeszkodzie, żeby stosować tę regułę także w sytuacji większej liczby rozgałęzień niż dwa, po prostu zawsze się dodaje pochodne z osobnych \"ścieżek\".\n",
        "\n",
        "<!-- \\\\ %ib: chyba nie jest to tak dobry przykład, jak myślałem...\n",
        "\n",
        "##### **Przykład:**\n",
        "Załóżmy, że mamy funkcję $f(x) = x\\cdot ln(x)$. Możemy ją przedstawić jako $f(x) = g(x)\\cdot h(x)$, gdzie $g(x)=x$ i $h(x)=ln(x)$. Korzystając z multivariable chain-rule możemy wyprowadzić:\n",
        "\n",
        "$$\\frac{\\partial f(x)}{\\partial x} = \\frac{\\partial g(x)h(x)}{\\partial x} = \\frac{\\partial g(x)h(x)}{\\partial g(x)} \\frac{\\partial g(x)}{\\partial x} + \\frac{\\partial g(x)h(x)}{\\partial h(x)} \\frac{\\partial h(x)}{\\partial x} = h(x)\\cdot 1 + g(x)\\cdot \\frac{1}{x} = ln(x) + 1$$\n",
        "\n",
        "Zwróć uwagę, że wzór na pochodną iloczynu jest szczególnym przypadkiem multivariable chain-rule:\n",
        "$$(g(x)h(x))' = g'(x)h(x) + g(x)h'(x) = 1\\cdot ln(x) + x\\cdot\\frac{1}{x} = ln(x) + 1$$ -->\n",
        "\n",
        "\\\\\n",
        "\n",
        "### Backpropagation\n",
        "\n",
        "Algorytm **wstecznej propagacji błędu** jest właściwie jedynie rozwinięciem **reguły delta**, która została przedstawiona na pierwszych zajęciach. Podobnie jak poprzednio, uczenie neuronów opisane jest w następujący sposób:\n",
        "\n",
        "$$w_i' = w_i - \\mu \\frac{\\partial L}{\\partial w_i} $$\n",
        "\n",
        "Jedyną różnicą jest sposób w jaki się wylicza gradient. Nawiązując do powyższych, krótkich wyjaśnień **chain-rule**, w podobny sposób należy traktować sieci neuronowe.\n",
        "\n",
        "**Dla warstwy wyjściowej** gradient można przedstawić następująco:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w_{ij}} = \\frac{\\partial L}{\\partial y_j} \\frac{\\partial y_j}{\\partial w_{ji}} = \\frac{\\partial L}{\\partial y_j} \\frac{\\partial y_j}{\\partial z_j}\\frac{\\partial z_j}{\\partial w_{ji}}$$\n",
        "\n",
        "Albo inaczej:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w_{ij}} = \\delta_j o_i$$\n",
        "\n",
        "gdzie $w_{ji}$ oznacza wagę połączenia pomiędzy neuronem $j$ a $i$, $\\delta_j = \\frac{\\partial L}{\\partial y_j} \\frac{\\partial y_j}{\\partial z_j}$ oraz $o_i$ to wyjście z neuronu $i$ (dla neuronów w pierwszej warstwie będą to wejścia do sieci, natomiast w kolejnych warstwach będą to wyjścia z neuronów poprzednich).\n",
        "\n",
        "**Dla warstwy ukrytej** sprawa nieco bardziej się komplikuje. Weźmy jako przykład następującą prostą sieć z 2 warstwami i łącznie 3 neuronami:\n",
        "\n",
        "![simplenet](https://drive.google.com/uc?id=1NXHjEWUX3gAbn8NnHh9eGWdQaSNDavKW)\n",
        "\n",
        "Dla warstwy wyjściowej możemy skorzystać jedynie z **chain-rule** uzyskując następujące równanie:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w^{2}_{i}} = \\frac{\\partial L}{\\partial y^{2}_i} \\frac{\\partial y^{2}_i}{\\partial z^{2}_i}\\frac{\\partial z^{2}_i}{\\partial w^{2}_{i}} = \\delta^2_i y^1_1$$\n",
        "\n",
        "Przy obliczaniu gradientu dla warstwy ukrytej najpierw stosujemy  proste **chain-rule**:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w^{1}_{1}} = \\frac{\\partial L}{\\partial y^{1}_1} \\frac{\\partial y^{1}_1}{\\partial z^{1}_1}\\frac{\\partial z^{1}_1}{\\partial w^{1}_{1}}$$\n",
        "\n",
        "W tym momencie można zauważyć, że jest możliwe zastosowanie **multivariable chain-rule** do wyrażenia $\\frac{\\partial L}{\\partial y^{1}_1}$ (ponieważ $L$ nie zależy bezpośrednio od $y^{1}_1$, oraz występuje \"rozgałęzienie\" od $y$):\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial y^{1}_1} = \\frac{\\partial L}{\\partial y^{2}_1} \\frac{\\partial y^{2}_1}{\\partial y^{1}_1} + \\frac{\\partial L}{\\partial y^{2}_2} \\frac{\\partial y^{2}_2}{\\partial y^{1}_1} = \\frac{\\partial L}{\\partial y^{2}_1} \\frac{\\partial y^{2}_1}{\\partial z^{2}_1}\\frac{\\partial z^{2}_1}{\\partial y^{1}_1} + \\frac{\\partial L}{\\partial y^{2}_2} \\frac{\\partial y^{2}_2}{\\partial z^{2}_2} \\frac{\\partial z^{2}_2}{\\partial y^{1}_1}$$\n",
        "\n",
        "Tu można zauważyć, że $\\frac{\\partial z^{2}_2}{\\partial y^{1}_1} = w^2_2$ oraz $\\frac{\\partial L}{\\partial y^{2}_2} \\frac{\\partial y^{2}_2}{\\partial z^{2}_2} = \\delta^2_2$ (przy założeniu liniowej funkcji aktywacji), co daje nam końcowo:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial y^{1}_1} = \\sum_i^2 \\delta^2_i w^2_i$$\n",
        "\n",
        "Podstawiając do wcześniejszego wzoru otrzymujemy:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w^{1}_{1}} = \\sum_i^2 \\delta^2_i w^2_i \\frac{\\partial y^{1}_1}{\\partial z^{1}_1}\\frac{\\partial z^{1}_1}{\\partial w^{1}_{1}}$$\n",
        "\n",
        "Ostatecznie, za pomocą następujących podstawień możemy sprowadzić powyższe równanie do wersji spójnej z gradientem dla warstwy wyjściowej:\n",
        "\n",
        "$$\\sum_i^2 \\delta^2_i w^2_i \\frac{\\partial y^{1}_1}{\\partial z^{1}_1} = \\delta^1_1$$\n",
        "$$\\frac{\\partial z^{1}_1}{\\partial w^{1}_{1}} = x$$\n",
        "$$\\frac{\\partial L}{\\partial w^{1}_{1}} = \\delta^1_1 x$$\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Podsumowując, zarówno dla warstwy wyjściowej jak i warstwy ukrytej gradienty możemy przedstawić w tej samej formie, składającej się z **błędu neuronu** ($\\delta$), oraz wyjścia z poprzedniej warstwy ($y$ lub $x$).\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w^{i}_{j}} = \\delta^i_j o^{(i-1)}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YViUnHJSf5vT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJKj35Ykeqzn"
      },
      "source": [
        "### Automatyczna wsteczna propagacja błędu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA3PfOaWcE9q"
      },
      "source": [
        "Można rozpatrywać różne algorytmy optymalizacji działające na bazie algorytmu wstecznej propagacji błędu, który sam w sobie jest po prostu pewną strategią przydziału informacji o błędzie do zmiennych, a to jak na tej podstawie będziemy je modyfikować pozostaje otwartą kwestią. Jednym z prostszych optymalizatorów jest **Stochastic Gradient Descent** (SGD). Różni się od klasycznego Gradient Descent tym, że w jego przypadku gradient liczony jest w każdej iteracji dla losowo wybranego podzbioru danych uczących zamiast dla wszystkich. Innym popularnym optymalizatorem jest **ADAM** (od \"adaptive moment estimation\"), który każdą zmienną modyfikuje na podstawie jej statystycznych momentów (rzędu 1 i 2) gradientu w pewnym oknie czasowym. Ogólnie konstruowanie optymalizatorów opartych na gradiencie to cała osobna obszerna dziedzina naukowa. Przykładowo, na niektórych problemach ADAM ma znacznie szybszą zbieżność niż SGD, ale na innych zauważalnie gorzej radzi sobie z uogólnieniem wiedzy i w efekcie błąd na zbiorze testowym jest większy.\n",
        "\n",
        "Poniżej zaprezentowany został algorytm wstecznej propagacji błędu zaimplementowany w bibliotece TensorFlow. Przykład składa się z definicji sieci neuronowej, funkcji straty oraz jednego kroku uczenia przy użyciu gotowego optymalizatora."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyUufSiJEgUH"
      },
      "source": [
        "### Prosta sieć neuronowa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ra9SuKPAE1wU"
      },
      "outputs": [],
      "source": [
        "# zmienne uczone pojedynczego neuronu, który na wejście otrzymuje wektor 10 liczb.\n",
        "w = tf.Variable(tf.ones([10, 1]))\n",
        "b = tf.Variable(tf.ones([1]))\n",
        "\n",
        "# definicja 1-warstwowej sieci neuronowej z funkcją aktywacji relu\n",
        "# (@ jest aliasem do tf.matmul())\n",
        "def network(x):\n",
        "  return tf.nn.relu(x @ w + b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c97P9HzdEnID"
      },
      "source": [
        "### Funkcja straty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAaD7jSpyUmk"
      },
      "source": [
        "W poniższym kodzie tf.reduce_mean to odpowiednik np.mean i działa tak samo. Jako drugi argument można podać wymiar, po którym liczona będzie średnia (domyślnie liczona jest z wszystkich wymiarów). Jeżeli chodzi o *reduce* (nazywane również *fold*) w nazwie, to jest to schemat obliczeń często wykorzystywany w paradygmacie programowania funkcyjnego, i polega na rekurencyjnym przechodzeniu przez strukturę przy jednoczesnym konstruowaniu nowej, w pewnym sensie redukując tę strukturę (np. macierz liczb) do nowej struktury (np. liczby)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sqwbPkFiE2UZ"
      },
      "outputs": [],
      "source": [
        "# mean squared error jako funkcja straty\n",
        "def loss(y_pred, y_true):\n",
        "  return tf.reduce_mean((y_pred - y_true) ** 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWv0Fg36Epug"
      },
      "source": [
        "### Obliczenie gradientu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "-ejn6iHQE2kw",
        "outputId": "c7566c02-35fc-462c-e41f-aea00caa9fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
            "array([[4.8256884],\n",
            "       [4.378417 ],\n",
            "       [4.399477 ],\n",
            "       [5.2734375],\n",
            "       [4.41467  ],\n",
            "       [4.5862827],\n",
            "       [4.8054414],\n",
            "       [6.2437496],\n",
            "       [5.066984 ],\n",
            "       [5.777932 ]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([9.8002615], dtype=float32)>]\n"
          ]
        }
      ],
      "source": [
        "# wsteczna propagacja błędu obsługiwana jest przez optymalizatory dostępne w bibliotece TensorFlow; tutaj użyliśmy Adam'a.\n",
        "optimizer = tf.optimizers.Adam(0.001)\n",
        "#optimizer = tf.optimizers.SGD(0.001)  # a tutaj Stochastic Gradient Descent\n",
        "\n",
        "# wejście oraz pożądane wyjście z sieci neuronowej\n",
        "x = tf.random.uniform([32, 10])\n",
        "y_true = tf.ones([32, 1])\n",
        "\n",
        "# obiekt gradient tape pozwala na \"nagrywanie\" pochodnych operacji wykonanych wewnątrz struktury \"with ... :\"\n",
        "with tf.GradientTape() as tape:\n",
        "  y_pred = network(x)\n",
        "  l = loss(y_pred, y_true)\n",
        "\n",
        "# pobranie interesujących nas gradientów (tylko dla uczonych zmiennych!)\n",
        "grads = tape.gradient(l, [w, b])\n",
        "# oraz ich użycie przez optymalizator\n",
        "optimizer.apply_gradients(zip(grads, [w, b]))\n",
        "\n",
        "print(grads)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idPo7uRZexv9"
      },
      "source": [
        "#### Zadanie 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFKkCPhgezMI"
      },
      "source": [
        "Korzystając z wiedzy z tych i poprzednich zajęć stwórz sieć neuronową składającą się z 3 warstw o rozmiarach odpowiednio 1, 2, 1. Niech w pierwszej i drugiej warstwie funkcją aktywacji będzie sigmoid a wyjście z sieci funkcją liniową. Skorzystaj z funkcji straty MSE.\n",
        "\n",
        "Naucz sieć neuronową, aby wykonywała funkcję **sinus** (wejściem sieci niech będzie kąt wyrażony w radianach). Trening sieci powinien polegać na wykonaniu algorytmu wstecznej propagacji błędu **ITERS** razy. Każda iteracja niech przetwarza **batch** danych o rozmiarze 16. Do nauki sieci wykorzystaj algorytm **Stochastic Gradient Descent** (tf.optimizers.SGD).\n",
        "\n",
        "W celu optymalizacji szybkości działania, dodaj do definicji modelu adnotację @tf.function.\n",
        "\n",
        "Przy domyślnych parametrach wyjdzie zasadniczo linia prosta na zerze. Poeksperymentuj z prędkością uczenia i liczbą iteracji, by poprawić ten rezultat. Sprawdź, jak działa ReLU dla tego problemu. Dla sigmoidalnej funkcji aktywacji rezultat powinien przypominać następujący wykres:\n",
        "![alt text](https://www.cs.put.poznan.pl/ibladek/students/eio/img/expected_sine.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "A2Urm0SzgDv-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 2000/2000\r"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import math\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ITERS = 2000\n",
        "\n",
        "act = tf.nn.sigmoid\n",
        "\n",
        "def loss(y_pred, y_true):\n",
        "  return tf.reduce_mean((y_pred - y_true) ** 2)\n",
        "\n",
        "# pierwsza warstwa\n",
        "w1 = tf.Variable(tf.ones([1, 1]))\n",
        "b1 = tf.Variable(tf.ones([1]))\n",
        "\n",
        "# druga warstwa\n",
        "w2 = tf.Variable(tf.ones([1, 2]))\n",
        "b2 = tf.Variable(tf.ones([2]))\n",
        "\n",
        "# trzecia warstwa\n",
        "w3 = tf.Variable(tf.ones([2, 1]))\n",
        "b3 = tf.Variable(tf.ones([1]))\n",
        "\n",
        "def layer_1(x):\n",
        "  return act(x @ w1 + b1)\n",
        "\n",
        "def layer_2(x):\n",
        "  return act(x @ w2 + b2)\n",
        "\n",
        "def layer_3(x):\n",
        "  return act(x @ w3 + b3)\n",
        "\n",
        "@tf.function\n",
        "def network(x):  # obliczanie wyjścia sieci\n",
        "  return layer_3(layer_2(layer_1(x)))\n",
        "\n",
        "mu = 0.01  # prędkość uczenia\n",
        "variables = [w1, b1, w2, b2, w3, b3]\n",
        "optimizer = tf.optimizers.Adam(mu)\n",
        "\n",
        "for i in range(ITERS):\n",
        "  x = tf.random.uniform([16, 1], 0, math.pi * 2)  # dane wejściowe\n",
        "  y_true = tf.math.sin(x)                         # dane uczące (ground truth)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred = network(x)\n",
        "    l = loss(y_pred, y_true)\n",
        "\n",
        "  grads = tape.gradient(l, variables)\n",
        "  optimizer.apply_gradients(zip(grads, variables))\n",
        "\n",
        "  print(f\"Epochs: {i+1}/{ITERS}\", end='\\r')\n",
        "\n",
        "\n",
        "# testowanie sieci na zbiorze testowym\n",
        "xs = np.linspace(0, 2 * math.pi, 100, dtype=np.float32).reshape([100, 1])  # wymiary są zmieniane by xs zostało zaakceptowane jako wejście do sieci\n",
        "ys1 = np.sin(xs)\n",
        "ys2 = network(xs)\n",
        "plt.plot(xs, ys1, xs, ys2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rePvYrKH51OD"
      },
      "source": [
        "#### Zadanie 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_yWbmVHhCWj"
      },
      "source": [
        "Wykonaj ponownie zadanie 2, tym razem samodzielnie implementując algorytm backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfcJ-fiiiK0i"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ITERS = 1000\n",
        "\n",
        "# pierwsza warstwa\n",
        "w1 = tf.Variable(tf.ones([1, 1]))\n",
        "b1 = tf.Variable(tf.ones([1]))\n",
        "\n",
        "# druga warstwa\n",
        "w2 = tf.Variable(tf.ones([1, 2]))\n",
        "b2 = tf.Variable(tf.ones([2]))\n",
        "\n",
        "# trzecia warstwa\n",
        "w3 = tf.Variable(tf.ones([2, 1]))\n",
        "b3 = tf.Variable(tf.ones([1]))\n",
        "\n",
        "def layer_1(x):\n",
        "  return act(x @ w1 + b1)\n",
        "\n",
        "def layer_2(x):\n",
        "  return act(x @ w2 + b2)\n",
        "\n",
        "def layer_3(x):\n",
        "  return act(x @ w3 + b3)\n",
        "\n",
        "@tf.function\n",
        "def network(x):  # obliczanie wyjścia sieci\n",
        "  return layer_3(layer_2(layer_1(x)))\n",
        "\n",
        "mu = 0.01  # prędkość uczenia\n",
        "for i in range(ITERS):\n",
        "  x = tf.random.uniform([16, 1], 0, math.pi * 2)  # dane wejściowe\n",
        "  y_true = tf.math.sin(x)                         # dane uczące (ground truth)\n",
        "\n",
        "  # propagacja wejścia sieci\n",
        "  z1 = x @ w1 + b1\n",
        "  y1 = act(z1)\n",
        "\n",
        "  z2 = y1 @ w2 + b2\n",
        "  y2 = act(z2)\n",
        "\n",
        "  z3 = y2 @ w3 + b3\n",
        "  y3 = act(z3)\n",
        "\n",
        "  y_pred = y3\n",
        "  l = loss(y_pred, y_true)\n",
        "\n",
        "  # grads = tape.gradient(l, variables)\n",
        "  # optimizer.apply_gradients(zip(grads, variables))\n",
        "\n",
        "  print(f\"Epochs: {i+1}/{ITERS}\", end='\\r')\n",
        "\n",
        "\n",
        "# testowanie sieci na zbiorze testowym\n",
        "xs = np.linspace(0, 2 * math.pi, 100, dtype=np.float32).reshape([100, 1])  # wymiary są zmieniane by xs zostało zaakceptowane jako wejście do sieci\n",
        "ys1 = np.sin(xs)\n",
        "ys2 = network(xs)\n",
        "plt.plot(xs, ys1, xs, ys2)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
